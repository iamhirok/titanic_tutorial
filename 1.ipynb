{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# タイタニック号の生存者予測\n",
    "\n",
    "\n",
    "　タイタニック号の事故では、2224人の乗客および乗組員のうち1502人が死亡したという。つまり半分以上が死亡したわけだが、性別や年齢、貧富で死亡率にばらつきがあった。<br>\n",
    "　今回は、どのような人々が生き残る可能性が高いのか分析する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題\n",
    "<h3>　すでに生死が判明している891名の個人情報を分析し、判明していない418名の生死について予測せよ。</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "つまり言い換えれば"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題\n",
    "<h3>　891個の訓練データの属性を分析し、418個の未知のデータについて二項分類せよ。</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　今回のように生死が判明している乗組員のデータが入手できる場合、**教師あり学習(Supervised learning)**を行うことができる。教師あり学習とは、与えられた**訓練データ(Training data)**をもとに予測を行うモデルを構築する手法のことである。<br>\n",
    "　また今回は生死のみを予測する問題である。生きてさえいれば容体に関わらずひとくくりに生存者として扱われる。このような2クラスの分類問題をとくに**二項分類(Binary classification)**という。<br>\n",
    "\n",
    "　訓練データが与えられた分類問題において用いられる機械学習アルゴリズムとして\n",
    " \n",
    "- サポートベクトルマシン\n",
    "- K近傍法\n",
    "- アンサンブル分類\n",
    "\n",
    "などがあげられる。<br>\n",
    " \n",
    "![](http://scikit-learn.org/stable/_static/ml_map.png)\n",
    "\n",
    "<a href=\"http://scikit-learn.org/stable/tutorial/machine_learning_map/\">機械学習ライブラリscikit-learnが提供するアルゴリズムのチートシート</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.ライブラリのインポート\n",
    "\n",
    "　では分析を始めよう。Pythonは機械学習に必要な機能を提供するライブラリが充実しているため、今回はPythonを採用する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn\n",
    "\n",
    "　scikit-learnはすでに構築済みの機械学習アルゴリズムを提供するライブラリである。これを用いることで、たとえ数理的な理解をしていなくても機械学習の実装が行える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "#!pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciPy\n",
    "\n",
    "　SciPyは高度な科学計算を提供するライブラリである。scikit-learnはこのライブラリを用いて(私たちの代わりに)高度な科学計算を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy\n",
    "#!pip3 install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "　Pandasはデータ解析ツールを提供するライブラリである。これを用いてデータを取り扱う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "#!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Matplotlib\n",
    " \n",
    " 　Matplotlibはグラフ描画ツールを提供するライブラリである。これを用いてグラフを描画する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "#!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy\n",
    "\n",
    "　Numpyは効率的な数値計算を提供するライブラリである。Pythonで数値計算を行う場合、必ずと言っていいほどNumpyが用いられる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "#!pip3 install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.データの読み込みと確認\n",
    "\n",
    "　まずCSVファイルからデータを読み取り、Pandasの提供するデータ構造、DataFrameに変換する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　trainの型を確認してみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確かに、CSVファイルから読み取ったデータがDataFrame型に変換されている。<br>\n",
    "　PandasはDataFrameのほかにSeriesというデータ構造も提供する。Seriesは一次元データのためのデータ構造である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　Pandasによるデータ解析では、多次元データのDataFrameと一次元データのSeriesが繰り返し登場する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　先ほど読み込んだtrainとtestのDataFrameを確認しよう。<br>\n",
    " 　headメソッドを用いることで、データ構造の上からn個のデータを表示できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　訓練データであるtrainは生存者Survivedに関する情報が与えられているが、テストデータであるtestには与えられていない。彼らの生存を予測することが今回の分析の目的である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　infoメソッドを用いることで、DataFrameに関する情報を表示することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　RangeIndexはそのDataFrameの行数を表している。このことからtrainとtestでそれぞれ891人と418人分のデータが存在することがわかる。しかし、例えばAgeのデータは、それぞれ714人と332人分しか存在していない。これはつまり一部データでAgeに関する情報が欠損していることを示している。同様に、CabinやEmbarkedでも欠損が確認できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "isnullメソッドを用いることで、データ構造の欠損(NaN)について確認できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.データクリーニング\n",
    "\n",
    "　学習の際に予測と関係のない不要な情報が混じっていると、それに引っ張られて予測の精度を落とすことがある。そこであらかじめ予測に役立ちそうな情報を選んでおく。またデータの欠損も埋めておく。\n",
    " \n",
    "|列名|意味|\n",
    "|---|---|\n",
    "|**PassengerId**|ID|\n",
    "|**\tPclass**|客室のグレード|\n",
    "|**Name**|名前|\n",
    "|**Sex**|性別|\n",
    "|**Age**|年齢|\n",
    "|**SibSp**|兄弟の数|\n",
    "|**Parch**|親や子の数|\n",
    "|**Ticket**|チケット番号|\n",
    "|**Fare**|乗船料金|\n",
    "|**Cabin**|部屋番号|\n",
    "|**Embarked**|乗船した港|\n",
    "\n",
    "　これらの属性のうち、例えばTicketやCabinは、生存を予測するにあたって必要な情報だろうか。確かにタイタニック号が沈むにあたって、浸水は船の底面から始まっただろうから、下層の客室ほど生存率は低いだろう。しかし部屋番号を表すCabinは欠損が多く、そもそも部屋番号と部屋の位置の対応づけができない(これはTicketについても同じことが言える)。<br>\n",
    "　しかも部屋の上下関係はPclassやFare反映されているだろうから、やはりTicketやCabinは必要ないだろう。\n",
    " \n",
    "|列名|意味|\n",
    "|---|---|\n",
    "|**PassengerId**|ID|\n",
    "|**\tPclass**|客室のグレード|\n",
    "|**Name**|名前|\n",
    "|**Sex**|性別|\n",
    "|**Age**|年齢|\n",
    "|**SibSp**|兄弟の数|\n",
    "|**Parch**|親や子の数|\n",
    "|**Fare**|乗船料金|\n",
    "|**Embarked**|乗船した港|\n",
    "\n",
    "　SibSpやParchについてはどうだろうか。例えば、親は子どもを生かそうとするだろうし、子どもが成人の場合は親を助けるかもしれない。Parchは残しておく価値があるだろう。兄弟についても、お互いに協力したり救出したりする可能性は十分に考えられるから、SibSpも有用な属性に思える。<br>\n",
    "　そこでSibSpとParchを合計したFamilyという属性を追加する。\n",
    " \n",
    "|列名|意味|\n",
    "|---|---|\n",
    "|**PassengerId**|ID|\n",
    "|**\tPclass**|客室のグレード|\n",
    "|**Name**|名前|\n",
    "|**Sex**|性別|\n",
    "|**Age**|年齢|\n",
    "|**SibSp**|兄弟の数|\n",
    "|**Parch**|親や子の数|\n",
    "|**Fare**|乗船料金|\n",
    "|**Embarked**|乗船した港|\n",
    "|**FamilySize**|家族の数|\n",
    "|**IsAlone**|家族の有無|\n",
    "\n",
    "　名前は生死の予測に寄与しない。しかし、名前についているMsやMrといった敬称は予測に使えるかもしれない。<br>\n",
    "　敬称を表す属性を追加しておく。\n",
    " \n",
    "|列名|意味|\n",
    "|---|---|\n",
    "|**PassengerId**|ID|\n",
    "|**\tPclass**|客室のグレード|\n",
    "|**Name**|名前|\n",
    "|**Sex**|性別|\n",
    "|**Age**|年齢|\n",
    "|**SibSp**|兄弟の数|\n",
    "|**Parch**|親や子の数|\n",
    "|**Fare**|乗船料金|\n",
    "|**Embarked**|乗船した港|\n",
    "|**FamilySize**|家族の数|\n",
    "|**IsAlone**|家族の有無|\n",
    "|**Title**|敬称|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　それでは実際にデータを加工しよう。<br>\n",
    " 　dropメソッドを用いることで、DataFrameの特定の列または行を削除することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [train, test]\n",
    "columns=['Ticket', 'Cabin']\n",
    "\n",
    "for dataset in datasets:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    dataset['IsAlone'] = 1\n",
    "    dataset.loc[dataset['FamilySize']  > 1, 'IsAlone'] = 0\n",
    "    dataset['Title'] = dataset['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "    dataset.drop(columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "value_countsメソッドを用いることで、要素の個数を表示することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　ちなみにvalue_countsメソッドで得られる型は"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一次元データなのでSeries型である。またPandasの提供するデータ構造では"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Title'].value_counts() < 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比較演算子を用いて各要素の真理値を出すこともできる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　DrやRevなど、極端に少ない敬称がいくつか確認できる。これらは外れ値とみなし、Otherという要素として扱うことにする。<br>\n",
    "　比較演算子を用いて外れ値を探し出し、敬称をOtherに書き換える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    title_names = (dataset['Title'].value_counts() < 10)\n",
    "    dataset['Title'] = dataset['Title'].apply(lambda x: 'Other' if title_names.loc[x] == True else x)\n",
    "    dataset.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　次にAge、EmbarkedそしてFareの欠損の処理を行う。処理方法はさまざまだが、今回はメディアンで欠損を補完する。<br>\n",
    "　fillnaメソッドを用いることで、データ構造の欠損(NaN)に値を代入できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n",
    "    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace = True)\n",
    "    dataset['Fare'].fillna(dataset['Fare'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　最後に、加工したデータをCSVファイルで保存しておく。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('./processed/train1.csv')\n",
    "test.to_csv('./processed/test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
